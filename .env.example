MASTER_LLM_API_KEY=
QUANTUM_LLM_ENDPOINT=https://quantum-llm.example.com/v1/generate
QUANTUM_LLM_API_KEY=
CODEHUB_USE_FOR_QUANTUM=true
CODEHUB_BACKEND_BASE_URL=http://127.0.0.1:8001
CODEHUB_GENERATE_ENDPOINT=/api/code/generate
CODEHUB_INTERNAL_API_KEY=
CODEHUB_BEARER_TOKEN=
CODEHUB_TIMEOUT=120
HF_API_KEY=hf_xxx
HF_INFERENCE_URL=https://router.huggingface.co/v1
HF_MODEL_ID=Qwen/Qwen2.5-7B-Instruct

MASTER_LLM_PROVIDER=auto
MASTER_LLM_MODEL=Qwen/Qwen2.5-7B-Instruct
MASTER_LLM_MAX_TOKENS=4096
MASTER_LLM_TEMPERATURE=0.1
ALLOW_RULE_BASED_FALLBACK=false

APP_ENV=production
LOG_LEVEL=INFO
MAX_RETRY_COUNT=5
MAX_LLM_RETRIES=3
SUBPROCESS_TIMEOUT=3600
MAX_CONCURRENT_EXPS=10
MAX_STATE_SIZE_KB=500

PROJECT_ROOT=./workspace/projects
STATE_DB_PATH=./workspace/state.db
KAGGLE_CONFIG_DIR=~/.kaggle

QUANTUM_ENABLED=true
KAGGLE_ENABLED=true
GPU_ALLOWED=false
WEBHOOK_ENABLED=false
ENABLE_PACKAGE_INSTALL=false
EXPERIMENT_VENV_ENABLED=true
AUTO_CONFIRM_LOW_RISK=true
LOW_RISK_PACKAGES=numpy,pandas,matplotlib,scikit-learn,requests
WORKFLOW_BACKGROUND_ENABLED=true
EXECUTION_MODE=vscode_extension
LOCAL_PYTHON_COMMAND=python
METRICS_TABLE_ENABLED=true
RL_ENABLED=true
RL_FEEDBACK_WINDOW=200
RL_MIN_SAMPLES_FOR_POLICY=5
FAILURE_INJECTION_ENABLED=false
FAILURE_INJECTION_RATE=0.0
FAILURE_INJECTION_POINTS=
AUTO_RETRY_ON_LOW_METRIC=true
MIN_PRIMARY_METRIC_FOR_SUCCESS=0.75
CHAT_CONTEXT_LIMIT_DEFAULT=5
CHAT_CONTEXT_LIMIT_MAX=20
CHAT_HISTORY_LIMIT=40
